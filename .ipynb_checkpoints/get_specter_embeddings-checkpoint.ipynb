{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import requests\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://model-apis.semanticscholar.org/specter/v1/invoke\"\n",
    "MAX_BATCH_SIZE = 16\n",
    "\n",
    "def chunks(lst, chunk_size=MAX_BATCH_SIZE):\n",
    "    \"\"\"Splits a longer list to respect batch size\"\"\"\n",
    "    for i in range(0, len(lst), chunk_size):\n",
    "        yield lst[i : i + chunk_size]\n",
    "        \n",
    "def embed(papers):\n",
    "    embeddings_by_paper_id: Dict[str, List[float]] = {}\n",
    "\n",
    "    for chunk in chunks(papers):\n",
    "        # Allow Python requests to convert the data above to JSON\n",
    "        response = requests.post(URL, json=chunk)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(response.status_code)\n",
    "            raise RuntimeError(\"Sorry, something went wrong, please try later!\")\n",
    "\n",
    "        for paper in response.json()[\"preds\"]:\n",
    "            embeddings_by_paper_id[paper[\"paper_id\"]] = paper[\"embedding\"]\n",
    "\n",
    "    return embeddings_by_paper_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_path = \"s3://lgo-theses-test/lgo_theses_eng_dept_class_year.csv\"\n",
    "merged_df_path = \"s3://lgo-theses-test/merged_mimo_df_preprocessed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "thesis_df = pd.read_csv(merged_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#make just a dataframe with id, thesis_title, and thesis content\n",
    "thesis_df[\"thesis_id\"]=thesis_df[\"Unnamed: 0\"]\n",
    "thesis_df_subset = thesis_df[[\"thesis_id\",\"THESIS_TITLE\",\"cleaned_thesis\"]]\n",
    "thesis_df_subset['title']=thesis_df_subset['THESIS_TITLE']\n",
    "thesis_df_subset['abstract']=thesis_df_subset[\"cleaned_thesis\"]\n",
    "thesis_df_subset['paper_id']=thesis_df_subset[\"thesis_id\"]\n",
    "\n",
    "thesis_df_for_json = thesis_df_subset[[\"paper_id\",\"title\",\"abstract\"]]\n",
    "\n",
    "thesis_df_for_json_test = thesis_df_for_json[0:4]\n",
    "thesis_df_for_json_test2 = thesis_df_for_json[4:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_embedding_dict_from_df(input_df):\n",
    "    max_value = len(thesis_df_for_json['paper_id'])\n",
    "    #max_value = 32\n",
    "    range_of_slicing_values = range(0,max_value,4)\n",
    "    embedding_dict = {}\n",
    "    for i in range_of_slicing_values:\n",
    "        if i!= max(range_of_slicing_values):\n",
    "            input_df_subset=input_df[i:i+4]\n",
    "            input_df_json = input_df_subset.to_dict('records')\n",
    "            try:\n",
    "                embeddings = embed(input_df_json)\n",
    "                embedding_dict.update(embeddings)\n",
    "                print(i)\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            input_df_subset_last = input_df[i:max(range_of_slicing_values)]\n",
    "            input_df_json_last = input_df_subset_last.to_dict('records')\n",
    "            embeddings_last = embed(input_df_json_last)\n",
    "            embedding_dict.update(embeddings_last)\n",
    "    print('Done')\n",
    "    return embedding_dict\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_dict_output = gen_embedding_dict_from_df(thesis_df_for_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_dict_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_embedding_json = json.dumps(embedding_dict_output)\n",
    "f=open(\"dict_all_embeddings.json\",\"w\")\n",
    "f.write(output_embedding_json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'ER1PANCR3N0J8K1G',\n",
       "  'HostId': 'GYw1LRqqr98KuLLnAKpOTRG0G5446xXblx39Kto2Y86Ew3ai8ueNfG6t3uoyyyIRsOOMIBgvQSQ=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'GYw1LRqqr98KuLLnAKpOTRG0G5446xXblx39Kto2Y86Ew3ai8ueNfG6t3uoyyyIRsOOMIBgvQSQ=',\n",
       "   'x-amz-request-id': 'ER1PANCR3N0J8K1G',\n",
       "   'date': 'Sat, 15 Aug 2020 21:37:22 GMT',\n",
       "   'etag': '\"3b47bde8754de2cc71541e84e40c78af\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"3b47bde8754de2cc71541e84e40c78af\"'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "json_object = output_embedding_json\n",
    "s3.put_object(\n",
    "     Body=str(json.dumps(json_object)),\n",
    "     Bucket='lgo-theses-test',\n",
    "     Key = 'dict_all_embeddings.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SAMPLE_PAPERS = [\n",
    "    {\n",
    "        \"paper_id\": \"A\",\n",
    "        \"title\": \"Microarray analysis of production cell lines to predict manufacturing viability\",\n",
    "        \"abstract\": \"Microarray analysis has long been used to evaluate cellular viability in a manufacturing environment. Most recently however...\",\n",
    "    },\n",
    "    {\n",
    "        \"paper_id\": \"B\",\n",
    "        \"title\": \"Economic recovery in developing nations: a case study\",\n",
    "        \"abstract\": \"Developing nations such as Africa are repeatedly targets of major disruptive events that occur...\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = embed(SAMPLE_PAPERS)\n",
    "\n",
    "output_embedding_json_test_questions = json.dumps(all_embeddings)\n",
    "f=open(\"dict_test_json_questions.json\",\"w\")\n",
    "f.write(output_embedding_json_test_questions)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
